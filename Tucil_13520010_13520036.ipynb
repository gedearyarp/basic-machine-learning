{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYG5JwZm7Nz1"
      },
      "source": [
        "# Tugas Kecil 1 Machine Learning\n",
        "13520010 - Ken Kalang Alqalyubi\n",
        "\n",
        "13520036 - I Gede Arya Raditya Parameswara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "NucRU0Gz2oAM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jumlah data training: [[9.029e+00 1.733e+01 5.879e+01 ... 1.750e-01 4.228e-01 1.175e-01]\n",
            " [2.109e+01 2.657e+01 1.427e+02 ... 2.903e-01 4.098e-01 1.284e-01]\n",
            " [9.173e+00 1.386e+01 5.920e+01 ... 5.087e-02 3.282e-01 8.490e-02]\n",
            " ...\n",
            " [1.429e+01 1.682e+01 9.030e+01 ... 3.333e-02 2.458e-01 6.120e-02]\n",
            " [1.398e+01 1.962e+01 9.112e+01 ... 1.827e-01 3.179e-01 1.055e-01]\n",
            " [1.218e+01 2.052e+01 7.722e+01 ... 7.431e-02 2.694e-01 6.878e-02]]\n",
            "Jumlah data testing: [[1.247e+01 1.860e+01 8.109e+01 ... 1.015e-01 3.014e-01 8.750e-02]\n",
            " [1.894e+01 2.131e+01 1.236e+02 ... 1.789e-01 2.551e-01 6.589e-02]\n",
            " [1.546e+01 1.948e+01 1.017e+02 ... 1.514e-01 2.837e-01 8.019e-02]\n",
            " ...\n",
            " [1.152e+01 1.493e+01 7.387e+01 ... 9.608e-02 2.664e-01 7.809e-02]\n",
            " [1.422e+01 2.785e+01 9.255e+01 ... 8.219e-02 1.890e-01 7.796e-02]\n",
            " [2.073e+01 3.112e+01 1.357e+02 ... 1.659e-01 2.868e-01 8.218e-02]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "import pickle\n",
        "\n",
        "breast_cancer_datasets = load_breast_cancer()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    breast_cancer_datasets.data,\n",
        "    breast_cancer_datasets.target,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Jumlah data training: {(X_train)}\")\n",
        "print(f\"Jumlah data testing: {(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "_pC7wK0y3AIG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/opt/homebrew/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC()"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import six\n",
        "import sys\n",
        "sys.modules['sklearn.externals.six'] = six\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from id3 import Id3Estimator\n",
        "from id3 import export_graphviz\n",
        "\n",
        "# Encoding data kategorikal\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "# ID3\n",
        "estimator = Id3Estimator()\n",
        "estimator = estimator.fit(X_train, y_train)\n",
        "\n",
        "# K Means\n",
        "kmeans = KMeans(n_clusters=2, random_state = 42)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "# LogisticRegression\n",
        "lg = LogisticRegression()\n",
        "lg.fit(X_train, y_train)\n",
        "\n",
        "# Multi-layer Perceptron Classifier (Neural Network)\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# SVC (Support Vector Classifier) Model\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "G1B7zOXy3DUP"
      },
      "outputs": [],
      "source": [
        "#Save model with pickle\n",
        "\n",
        "# Decision Tree Classifier\n",
        "with open('decision_tree_model.pkl', 'wb') as file:\n",
        "    pickle.dump(dtc, file)\n",
        "    \n",
        "# ID3\n",
        "with open('id3_model.pkl', 'wb') as file:\n",
        "    pickle.dump(estimator, file)\n",
        "\n",
        "# K Means\n",
        "with open('k_means.pkl', 'wb') as file:\n",
        "    pickle.dump(kmeans, file)\n",
        "\n",
        "# Logistic Regression\n",
        "with open('logistic_regression_model.pkl', 'wb') as file:\n",
        "    pickle.dump(lg, file)\n",
        "\n",
        "\n",
        "# Multi-layer Perceptron Classifier (Neural Network)\n",
        "with open('multi-layer_perceptron_classifier_model.pkl', 'wb') as file:\n",
        "    pickle.dump(mlp, file)\n",
        "\n",
        "# SVC Model\n",
        "with open('svc_model.pkl', 'wb') as file:\n",
        "    pickle.dump(svc, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "_uAjlK7P3FK8"
      },
      "outputs": [],
      "source": [
        "#Load File\n",
        "\n",
        "# Decision Tree Classifier\n",
        "with open('decision_tree_model.pkl', 'rb') as file:\n",
        "    dtc = pickle.load(file)\n",
        "\n",
        "# ID3\n",
        "with open('id3_model.pkl', 'rb') as file:\n",
        "    estimator = pickle.load(file)\n",
        "\n",
        "# K Means\n",
        "with open('k_means.pkl', 'rb') as file:\n",
        "    kmeans = pickle.load(file)\n",
        "\n",
        "# Logistic Regression\n",
        "with open('logistic_regression_model.pkl', 'rb') as file:\n",
        "    lg = pickle.load( file)\n",
        "\n",
        "# Multi-layer Perceptron Classifier (Neural Network)\n",
        "with open('multi-layer_perceptron_classifier_model.pkl', 'rb') as file:\n",
        "    mlp = pickle.load( file)\n",
        "\n",
        "# SVC Model\n",
        "with open('svc_model.pkl', 'rb') as file:\n",
        "    svc = pickle.load(file)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "9hlYIvLi3Gz3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Decision Tree Classifier:\n",
            "\n",
            "Accuracy: 0.9385964912280702\n",
            "Precision: 0.9444444444444444\n",
            "Recall: 0.9577464788732394\n",
            "F1 Score: 0.951048951048951\n",
            "Confusion Matrix:\n",
            "[[39  4]\n",
            " [ 3 68]]\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree Classifier\n",
        "print(\"Model Decision Tree Classifier:\\n\")\n",
        "y_pred_Dtc = dtc.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracyDtc = accuracy_score(y_test, y_pred_Dtc)\n",
        "precisionDtc = precision_score(y_test, y_pred_Dtc)\n",
        "recallDtc = recall_score(y_test, y_pred_Dtc)\n",
        "f1Dtc = f1_score(y_test, y_pred_Dtc)\n",
        "print(\"Accuracy:\", accuracyDtc)\n",
        "print(\"Precision:\", precisionDtc)\n",
        "print(\"Recall:\", recallDtc)\n",
        "print(\"F1 Score:\", f1Dtc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cmDtc = confusion_matrix(y_test, y_pred_Dtc)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cmDtc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Ys6Tk5wu3ICw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Id3 Model:\n",
            "\n",
            "Accuracy: 0.9385964912280702\n",
            "Precision: 0.9324324324324325\n",
            "Recall: 0.971830985915493\n",
            "F1 Score: 0.9517241379310345\n",
            "Confusion Matrix:\n",
            "[[38  5]\n",
            " [ 2 69]]\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree Id3\n",
        "print(\"Decision Tree Id3 Model:\\n\")\n",
        "y_pred_id3 = estimator.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_id3 = accuracy_score(y_test, y_pred_id3)\n",
        "precision_id3 = precision_score(y_test, y_pred_id3)\n",
        "recall_id3 = recall_score(y_test, y_pred_id3)\n",
        "f1_id3 = f1_score(y_test, y_pred_id3)\n",
        "print(\"Accuracy:\", accuracy_id3)\n",
        "print(\"Precision:\", precision_id3)\n",
        "print(\"Recall:\", recall_id3)\n",
        "print(\"F1 Score:\", f1_id3)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_id3 = confusion_matrix(y_test, y_pred_id3)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_id3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "AxtYWfTG3Jmg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model K-Means:\n",
            "\n",
            "Accuracy: 0.12280701754385964\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "Confusion Matrix:\n",
            "[[14 29]\n",
            " [71  0]]\n"
          ]
        }
      ],
      "source": [
        "# K Means\n",
        "\n",
        "print(\"Model K-Means:\\n\")\n",
        "y_pred_Kmeans = kmeans.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_Kmeans = accuracy_score(y_test, y_pred_Kmeans)\n",
        "precision_Kmeans = precision_score(y_test, y_pred_Kmeans)\n",
        "recall_Kmeans = recall_score(y_test, y_pred_Kmeans)\n",
        "f1_Kmeans = f1_score(y_test, y_pred_Kmeans)\n",
        "print(\"Accuracy:\", accuracy_Kmeans)\n",
        "print(\"Precision:\", precision_Kmeans)\n",
        "print(\"Recall:\", recall_Kmeans)\n",
        "print(\"F1 Score:\", f1_Kmeans)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_Kmeans = confusion_matrix(y_test, y_pred_Kmeans)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_Kmeans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "1FEiSv5d3LAZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression:\n",
            "\n",
            "Accuracy: 0.956140350877193\n",
            "Precision: 0.9459459459459459\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.9655172413793103\n",
            "Confusion Matrix:\n",
            "[[39  4]\n",
            " [ 1 70]]\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "print(\"Logistic Regression:\\n\")\n",
        "y_pred_lg = lg.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_lg = accuracy_score(y_test, y_pred_lg)\n",
        "precision_lg = precision_score(y_test, y_pred_lg)\n",
        "recall_lg = recall_score(y_test, y_pred_lg)\n",
        "f1_lg = f1_score(y_test, y_pred_lg)\n",
        "print(\"Accuracy:\", accuracy_lg)\n",
        "print(\"Precision:\", precision_lg)\n",
        "print(\"Recall:\", recall_lg)\n",
        "print(\"F1 Score:\", f1_lg)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_lg = confusion_matrix(y_test, y_pred_lg)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_lg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "reJ2_gXe3MZP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Neural Network:\n",
            "\n",
            "Accuracy: 0.956140350877193\n",
            "Precision: 0.9583333333333334\n",
            "Recall: 0.971830985915493\n",
            "F1 Score: 0.965034965034965\n",
            "Confusion Matrix:\n",
            "[[40  3]\n",
            " [ 2 69]]\n"
          ]
        }
      ],
      "source": [
        "# Multi-layer Perceptron Classifier\n",
        "print(\"Model Neural Network:\\n\")\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp)\n",
        "print(\"Accuracy:\", accuracy_mlp)\n",
        "print(\"Precision:\", precision_mlp)\n",
        "print(\"Recall:\", recall_mlp)\n",
        "print(\"F1 Score:\", f1_mlp)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "VPMyKT6c3N8V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC Model:\n",
            "\n",
            "Accuracy: 0.9473684210526315\n",
            "Precision: 0.922077922077922\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9594594594594594\n",
            "Confusion Matrix:\n",
            "[[37  6]\n",
            " [ 0 71]]\n"
          ]
        }
      ],
      "source": [
        "# SVC Model\n",
        "print(\"SVC Model:\\n\")\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "precision_svc = precision_score(y_test, y_pred_svc)\n",
        "recall_svc = recall_score(y_test, y_pred_svc)\n",
        "f1_svc = f1_score(y_test, y_pred_svc)\n",
        "print(\"Accuracy:\", accuracy_svc)\n",
        "print(\"Precision:\", precision_svc)\n",
        "print(\"Recall:\", recall_svc)\n",
        "print(\"F1 Score:\", f1_svc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_svc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb58jNvI69ZO"
      },
      "source": [
        "## Analisis Perbandingan Model\n",
        "Berdasarkan hasil metrik evaluasi yang diperoleh dari seluruh model, dapat disimpulkan pada rata-ratanya bahwa model Neural Network dan Logistic Regression memberikan performa yang sangat baik pada nilai akurasinya. Kedua model ini memiliki nilai presisi, recall, dan F1 score yang cukup tinggi, menunjukkan bahwa model tersebut dapat memprediksi dengan akurat dan memiliki tingkat kesalahan yang rendah. Dari confusion matrix, dapat dilihat bahwa kedua model ini memiliki jumlah false negative dan false positive yang rendah, sehingga model ini dapat diandalkan untuk membuat prediksi yang akurat.\n",
        "\n",
        "Sedangkan, model Decision Tree Classifier dan Decision Tree Id3 Model memiliki performa yang cukup baik berdasarkan nilai akurasinya. Kedua model ini memiliki nilai presisi dan recall yang baik, serta F1 score yang cukup tinggi. Dari confusion matrix, dapat dilihat bahwa kedua model ini memiliki jumlah false negative dan false positive yang rendah, sehingga model ini dapat diandalkan untuk membuat prediksi yang akurat.\n",
        "\n",
        "Namun, model K-Means dan SVC memiliki performa yang buruk dibandingkan dengan model lainnya. Model K-Means memiliki nilai akurasi, presisi, recall, dan F1 score yang semuanya sangat rendah, menunjukkan bahwa model ini tidak dapat memprediksi dengan baik. Sedangkan model SVC memiliki nilai presisi yang cukup baik, tetapi recall-nya sangat tinggi, sehingga model ini dapat mengidentifikasi kebanyakan kasus positif, tetapi mungkin akan melewatkan beberapa kasus negatif."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ZjHbQoVFBoNT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Classifier k-fold cross validation:\n",
            "\n",
            "Accuracy:  0.9473684210526315\n",
            "F1-Score:  0.9577464788732394\n"
          ]
        }
      ],
      "source": [
        "dtcCross = DecisionTreeClassifier()\n",
        "scoring = ['accuracy', 'f1']\n",
        "cv_results = cross_validate(dtcCross, X_train, y_train, cv=10, scoring=scoring)\n",
        "\n",
        "dtcCross.fit(X_train, y_train)\n",
        "\n",
        "y_cross_pred = dtcCross.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree Classifier k-fold cross validation:\\n\")\n",
        "\n",
        "# Menampilkan hasil cross-validation\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_cross_pred))\n",
        "print(\"F1-Score: \", f1_score(y_test, y_cross_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6g5YvypxBUMT"
      },
      "source": [
        "## Analisis Perbandingan DecisionTreeClassifier\n",
        "Berdasarkan hasil yang diperoleh, nilai akurasi dan F1-score dari penggunaan 10-fold cross validation pada model Decision Tree Classifier realatif lebih besar dibandingkan dengan hasil akurasi dan F1-score model Decision Tree Classifier sebelumnya. Meskipun selisihnya tidak terlalu signifikan. Ini mungkin disebabkan oleh beberapa data yang mungkin mengalami overfitting pada model Decision Tree Classifier, dan dilakukan validasi pada data yang sama selama k iterasi, sehingga membuat model tidak terlalu bervariasi.\n",
        "\n",
        "Penggunaan k-fold cross validation tetap berguna dalam menghindari overfitting dan underfitting pada model, dan memberikan ukuran kinerja model yang lebih akurat. Dalam hal ini, hasil evaluasi dari 10-fold cross validation memberikan gambaran yang lebih representatif tentang kinerja model, terutama dalam menghadapi kasus dataset yang besar dan kompleks. Oleh karena itu, k-fold cross validation tetap menjadi suatu teknik yang penting dalam evaluasi kinerja model di bidang pembelajaran mesin."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
